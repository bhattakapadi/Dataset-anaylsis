{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "import face_recognition\n",
    "from PIL import Image\n",
    "import os\n",
    "from os import listdir\n",
    "#from multiprocessing import Pool #mission impossible currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import torch.nn.functional as F\n",
    "from emotion_detection.fer_data_utils import SkResize, HistEq, AddChannel, ToRGB\n",
    "from vision_utils.custom_architectures import SepConvModel\n",
    "#extra added\n",
    "from vision_utils.custom_architectures import SepConvModel, initialize_model, PretrainedMT\n",
    "from multitask_rag.evaluate import predict_utk as test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHSEPCONV='/home/manish//Documents/democlassi/emotion-detection/sepconv_model_55_val_loss=1.175765.pth'\n",
    "PATHRESNETAGR='/home/manish/Documents/democlassi/other/resnet_model_21_val_loss=4.275671.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#emotion\n",
    "model = SepConvModel()\n",
    "model.load_state_dict(torch.load(PATHSEPCONV, map_location=\"cpu\"))\n",
    "\n",
    "#age-race-gender\n",
    "resnet_model_agr = PretrainedMT(model_name='resnet')\n",
    "resnet_model_agr.load_state_dict(torch.load(PATHRESNETAGR, map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    #transforms.Resize((500,500),Image.Resampling.LANCZOS),\n",
    "    transforms.Resize((200,200),Image.Resampling.LANCZOS),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these two function are needed doesn't work by just importing these function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def democlassiEvaluate(pil_image,):\n",
    "    \n",
    "    img_tensor= data_transforms(pil_image) \n",
    "    imge = pil_image.convert('L')\n",
    "    img = imge.resize((120,120),Image.Resampling.LANCZOS)\n",
    "    numpydata = asarray(img)\n",
    "    res1=predict_fer(numpydata,model,True)\n",
    "    # with resent model--age--race--gender\n",
    "    #res2=test_image(img_tensor,resnet_model)\n",
    "    #with sep_conv_model --age--gender---race\n",
    "    #res2=test_image(img_tensor,sep_conv_model)\n",
    "    #with VGG model ---age--race--gender\n",
    "    #res2=test_image(img_tensor,vgg_model_agr)\n",
    "    \n",
    "    #for resnet model\n",
    "    res2 = test_image(img_tensor,resnet_model_agr)\n",
    "    \n",
    "    #for sepconv_ model\n",
    "    #res2 = test_image(img_tensor,sepconv_model_agr)\n",
    "    return res1,res2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepfaceOutput(obj1):\n",
    "    print(\"Deepface comparision\")\n",
    "    print(\"----Deepface---\")\n",
    "    print(\"Age:---\",{obj1['age']},\"---\")\n",
    "    print(\"Gender:---\",{obj1['gender']},\"---\")\n",
    "    print(\"Race:---\",{obj1['dominant_race']},\"---\")\n",
    "    print(\"Emotion:---\",{obj1['dominant_emotion']},\"---\")\n",
    "    print('------------------------------------------- ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fer(image, model, transf_learn=True):\n",
    "\n",
    "    # process image\n",
    "    image = preprocess_fer(image, transf_learn)\n",
    "    \n",
    "    # prepare model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    image = image.to(device)\n",
    "\n",
    "    # predict probabilities\n",
    "    emotion = F.softmax(model(image), dim=1).detach().to('cpu').numpy()[0]\n",
    "    target_names = ['Angry', 'Disgusted', 'Afraid', 'Happy', 'Sad', 'Surprised', 'Neutral']\n",
    "    pred_label = target_names[np.argmax(emotion)]\n",
    "\n",
    "    emotion_probs = dict(zip(target_names, emotion))\n",
    "\n",
    "    return emotion_probs, pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fer(image, transf_learn):\n",
    "    if transf_learn:\n",
    "        transf = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    else:\n",
    "        transf = transforms.Compose([\n",
    "            HistEq(),\n",
    "            AddChannel(),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        print(transf(image))  \n",
    "\n",
    "    return transf(image).to(torch.float32).unsqueeze_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evalution stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create outer class\n",
    "class Stats:\n",
    "\tdef __init__(self,framework,gender):\n",
    "\t\tself.framework = framework\n",
    "\t\tself.gender = gender\n",
    "\t\tself.count = 0\n",
    "\t\tself.age = 0\n",
    "        \n",
    "\n",
    "\t# create a 1st Inner class\n",
    "\tclass Race:\n",
    "\t\tdef __init__(self):\n",
    "\t\t\tself.white = 0\n",
    "\t\t\tself.black = 0\n",
    "\t\t\tself.asian = 0\n",
    "\t\t\tself.indian = 0\n",
    "\t\t\tself.unknown = 0\n",
    "\n",
    "\n",
    "\t# create a 2nd Inner class\n",
    "\tclass Emotion:\n",
    "\t\tdef __init__(self):\n",
    "\t\t\tself.angry = 0\n",
    "\t\t\tself.disgust = 0\n",
    "\t\t\tself.fear = 0\n",
    "\t\t\tself.happy = 0\n",
    "\t\t\tself.sad = 0\n",
    "\t\t\tself.suprise = 0\n",
    "\t\t\tself.neutral = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDemoClassiOutput(res1,res2):\n",
    "    print(\"Democlassi comparision\")\n",
    "    print(\"---Democlassi---\")\n",
    "    print(\"Age:---\",{round(res2[0], 0)},\"---\")\n",
    "    print(\"Gender:---\",{res2[2]},\"---\")\n",
    "    print(\"Race:---\",{res2[4]},\"---\")\n",
    "    print(\"Emotion:---\",{res1[1]},\"---\") #res1 for emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepfaceStats(stats,obj):\n",
    "    stats.age = stats.age + obj['age']\n",
    "    stats.count = stats.count + 1 \n",
    "    \n",
    "    if obj['dominant_race'] == \"white\":\n",
    "        stats.race.white = stats.race.white+1\n",
    "    elif obj['dominant_race']  == \"black\":\n",
    "        stats.race.black = stats.race.black+1\n",
    "    elif obj['dominant_race']  == \"asian\":\n",
    "        stats.race.asian = stats.race.asian+1\n",
    "    elif obj['dominant_race']  == \"indian\":\n",
    "        stats.race.indian = stats.race.indian+1\n",
    "    else:\n",
    "        stats.race.unknown = stats.race.unknown+1\n",
    "        \n",
    "        \n",
    "    if obj['dominant_emotion']== \"angry\":\n",
    "        stats.emotion.angry= stats.emotion.angry+1\n",
    "    elif obj ['dominant_emotion'] == \"disgust\":\n",
    "        stats.emotion.disgust = stats.emotion.disgust+1\n",
    "    elif obj['dominant_emotion']== \"afraid\":\n",
    "        stats.emotion.afraid = stats.emotion.afraid+1\n",
    "    elif obj['dominant_emotion']== \"happy\":\n",
    "        stats.emotion.happy = stats.emotion.happy+1\n",
    "    elif obj['dominant_emotion'] == \"sad\":\n",
    "        stats.emotion.sad = stats.emotion.sad+1\n",
    "    elif obj['dominant_emotion'] == \"surprised\":\n",
    "        stats.emotion.suprise = stats.emotion.suprise+1\n",
    "    else:\n",
    "        stats.emotion.neutral = stats.emotion.neutral+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classiStats(stats,res1,res2):\n",
    "    stats.age = stats.age + round(res2[0],0)\n",
    "    stats.count = stats.count + 1 \n",
    "    \n",
    "    if res2[4] == \"White\":\n",
    "        stats.race.white = stats.race.white+1\n",
    "    elif res2[4] == \"Black\":\n",
    "        stats.race.black = stats.race.black+1\n",
    "    elif res2[4] == \"Asian\":\n",
    "        stats.race.asian = stats.race.asian+1\n",
    "    elif res2[4] == \"Indian\":\n",
    "        stats.race.indian = stats.race.indian+1\n",
    "    else:\n",
    "        stats.race.unknown = stats.race.unknown+1\n",
    "        \n",
    "        \n",
    "    if res1[1] == \"Angry\":\n",
    "        stats.emotion.angry= stats.emotion.angry+1\n",
    "    elif res1[1] == \"Disgusted\":\n",
    "        stats.emotion.disgust = stats.emotion.disgust+1\n",
    "    elif res1[1] == \"Afraid\":\n",
    "        stats.emotion.afraid = stats.emotion.afraid+1\n",
    "    elif res1[1] == \"Happy\":\n",
    "        stats.emotion.happy = stats.emotion.happy+1\n",
    "    elif res1[1] == \"Sad\":\n",
    "        stats.emotion.sad = stats.emotion.sad+1\n",
    "    elif res1[1] == \"Surprised\":\n",
    "        stats.emotion.suprise = stats.emotion.suprise+1\n",
    "    else:\n",
    "        stats.emotion.neutral = stats.emotion.neutral+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateDemoclassi(folder_dir, save_dir,statsmen,statswomen):\n",
    "    for images in os.listdir(folder_dir):\n",
    "        if (images.endswith(\".png\") or images.endswith(\".jpg\")or images.endswith(\".jpeg\")):\n",
    "            new=folder_dir+\"/\"+images\n",
    "            print(new)\n",
    "            image = face_recognition.load_image_file(new)\n",
    "            face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model=\"resnet\")\n",
    "            if len(face_locations) != 0 :\n",
    "                for face_location in face_locations:\n",
    "                    top, right, bottom, left = face_location\n",
    "                    face_image = image[top:bottom,left:right]\n",
    "                    pil_img = Image.fromarray(face_image)\n",
    "                    pil_image = pil_img.resize((400,400),Image.Resampling.LANCZOS)\n",
    "                    res1, res2 = democlassiEvaluate(pil_image)\n",
    "                    \n",
    "                    if res2[2].lower() == \"man\" :\n",
    "                        classiStats(statsmen,res1,res2)\n",
    "                    else:\n",
    "                        classiStats(statswomen,res1,res2)\n",
    "                    #democlassiOutput(res1,res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateDeepface(folder_dir, save_dir,deepstatsMen,deepstatsWomen):\n",
    "    for images in os.listdir(folder_dir):\n",
    "        if (images.endswith(\".png\") or images.endswith(\".jpg\")or images.endswith(\".jpeg\")):\n",
    "            new=folder_dir+\"/\"+images\n",
    "            print(new)\n",
    "            image = face_recognition.load_image_file(new)\n",
    "            face_locations = face_recognition.face_locations(image, number_of_times_to_upsample=0, model=\"resnet\")\n",
    "            if len(face_locations) != 0 :\n",
    "                for face_location in face_locations:\n",
    "                    top, right, bottom, left = face_location\n",
    "                    face_image = image[top:bottom,left:right]\n",
    "                    pil_img = Image.fromarray(face_image)\n",
    "                    pil_image = pil_img.resize((400,400),Image.Resampling.LANCZOS)\n",
    "                    fileLocation=save_dir+'/'+'tmp.jpg'\n",
    "                    pil_image.save(fileLocation,\"JPEG\")\n",
    "                    obj= DeepFace.analyze(img_path=fileLocation, enforce_detection=False)\n",
    "                    \n",
    "                    if obj[\"gender\"] == \"Man\" :\n",
    "                        deepfaceStats(deepstatsMen,obj)\n",
    "                    else:\n",
    "                        deepfaceStats(deepstatsWomen,obj)\n",
    "                        \n",
    "                    deepfaceOutput(obj)\n",
    "                        \n",
    "                    #printDemoClassiOutput(obj)\n",
    "    #print('++++++++++++++++++++++++++++++++++++++++++')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printStats(stats):\n",
    "    if stats.count  != 0 :\n",
    "        print(\"Number of picture analyzed by the \"+str(stats.count))\n",
    "        averageAge = stats.age / stats.count \n",
    "        print(\"average age:\" + str(averageAge))\n",
    "\n",
    "        print(\"-----------------Race------------------\")\n",
    "        print(\"White: \"+ str(stats.race.white))\n",
    "        print(\"Black: \" + str(stats.race.black))\n",
    "        print(\"Asian:\" +str(stats.race.asian))\n",
    "        print(\"Indian: \" + str(stats.race.indian))\n",
    "        print(\"Unknown: \" + str(stats.race.unknown))\n",
    "\n",
    "        print(\"---------Emotion------------------\")\n",
    "        print(\"Angry: \" + str(stats.emotion.angry))\n",
    "        print(\"Disgust: \" + str(stats.emotion.disgust))\n",
    "        print(\"fear: \" + str(stats.emotion.fear))\n",
    "        print(\"Hppy: \" + str(stats.emotion.happy))\n",
    "        print(\"sad: \" + str(stats.emotion.sad))\n",
    "        print(\"Suprise:\" + str(stats.emotion.suprise))\n",
    "        print(\"neutral: \" + str(stats.emotion.neutral) )\n",
    "    else: \n",
    "        print(\"no stats for detected\"+stats.framework +\" for \"+ stats.gender)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/manish/fotos-form-download/image327.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:  25%|██▌       | 1/4 [00:00<00:00,  5.38it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|█████     | 2/4 [00:01<00:01,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 729ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  75%|███████▌  | 3/4 [00:02<00:00,  1.13it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 748ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:03<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepface comparision\n",
      "----Deepface---\n",
      "Age:--- {40} ---\n",
      "Gender:--- {'Man'} ---\n",
      "Race:--- {'middle eastern'} ---\n",
      "Emotion:--- {'neutral'} ---\n",
      "------------------------------------------- \n",
      "/home/manish/fotos-form-download/image264.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Action: emotion:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:  25%|██▌       | 1/4 [00:00<00:00,  8.69it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 728ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|█████     | 2/4 [00:01<00:01,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 993ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  75%|███████▌  | 3/4 [00:02<00:00,  1.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:03<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepface comparision\n",
      "----Deepface---\n",
      "Age:--- {28} ---\n",
      "Gender:--- {'Man'} ---\n",
      "Race:--- {'white'} ---\n",
      "Emotion:--- {'happy'} ---\n",
      "------------------------------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:  25%|██▌       | 1/4 [00:00<00:00,  3.82it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 681ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|█████     | 2/4 [00:01<00:01,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 683ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  75%|███████▌  | 3/4 [00:01<00:00,  1.40it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 692ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:02<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepface comparision\n",
      "----Deepface---\n",
      "Age:--- {25} ---\n",
      "Gender:--- {'Man'} ---\n",
      "Race:--- {'white'} ---\n",
      "Emotion:--- {'happy'} ---\n",
      "------------------------------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:  25%|██▌       | 1/4 [00:00<00:00,  5.22it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 704ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|█████     | 2/4 [00:01<00:01,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 697ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  75%|███████▌  | 3/4 [00:01<00:00,  1.45it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 727ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepface comparision\n",
      "----Deepface---\n",
      "Age:--- {28} ---\n",
      "Gender:--- {'Man'} ---\n",
      "Race:--- {'white'} ---\n",
      "Emotion:--- {'happy'} ---\n",
      "------------------------------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:  25%|██▌       | 1/4 [00:00<00:00,  5.39it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 905ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|█████     | 2/4 [00:01<00:01,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 936ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  75%|███████▌  | 3/4 [00:02<00:00,  1.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 696ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:03<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepface comparision\n",
      "----Deepface---\n",
      "Age:--- {34} ---\n",
      "Gender:--- {'Man'} ---\n",
      "Race:--- {'white'} ---\n",
      "Emotion:--- {'fear'} ---\n",
      "------------------------------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:  25%|██▌       | 1/4 [00:00<00:00,  5.56it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 716ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|█████     | 2/4 [00:01<00:01,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 686ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  75%|███████▌  | 3/4 [00:01<00:00,  1.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 734ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepface comparision\n",
      "----Deepface---\n",
      "Age:--- {29} ---\n",
      "Gender:--- {'Man'} ---\n",
      "Race:--- {'white'} ---\n",
      "Emotion:--- {'fear'} ---\n",
      "------------------------------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 37ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:  25%|██▌       | 1/4 [00:00<00:00,  5.07it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 686ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|█████     | 2/4 [00:01<00:01,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 702ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  75%|███████▌  | 3/4 [00:01<00:00,  1.45it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 807ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:02<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepface comparision\n",
      "----Deepface---\n",
      "Age:--- {33} ---\n",
      "Gender:--- {'Man'} ---\n",
      "Race:--- {'latino hispanic'} ---\n",
      "Emotion:--- {'happy'} ---\n",
      "------------------------------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:  25%|██▌       | 1/4 [00:00<00:00,  4.95it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 753ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|█████     | 2/4 [00:01<00:01,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 697ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  75%|███████▌  | 3/4 [00:01<00:00,  1.39it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 708ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:02<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepface comparision\n",
      "----Deepface---\n",
      "Age:--- {34} ---\n",
      "Gender:--- {'Man'} ---\n",
      "Race:--- {'white'} ---\n",
      "Emotion:--- {'neutral'} ---\n",
      "------------------------------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:  25%|██▌       | 1/4 [00:00<00:00,  5.65it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 710ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|█████     | 2/4 [00:01<00:01,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 718ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  75%|███████▌  | 3/4 [00:01<00:00,  1.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 718ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepface comparision\n",
      "----Deepface---\n",
      "Age:--- {28} ---\n",
      "Gender:--- {'Man'} ---\n",
      "Race:--- {'white'} ---\n",
      "Emotion:--- {'fear'} ---\n",
      "------------------------------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:  25%|██▌       | 1/4 [00:00<00:00,  5.70it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 675ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|█████     | 2/4 [00:01<00:01,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 699ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  75%|███████▌  | 3/4 [00:01<00:00,  1.45it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 699ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepface comparision\n",
      "----Deepface---\n",
      "Age:--- {22} ---\n",
      "Gender:--- {'Man'} ---\n",
      "Race:--- {'white'} ---\n",
      "Emotion:--- {'sad'} ---\n",
      "------------------------------------------- \n",
      "/home/manish/fotos-form-download/image291.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Action: emotion:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:  25%|██▌       | 1/4 [00:00<00:00,  8.01it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 688ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|█████     | 2/4 [00:00<00:01,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 723ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  75%|███████▌  | 3/4 [00:01<00:00,  1.45it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:02<00:00,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepface comparision\n",
      "----Deepface---\n",
      "Age:--- {37} ---\n",
      "Gender:--- {'Man'} ---\n",
      "Race:--- {'white'} ---\n",
      "Emotion:--- {'angry'} ---\n",
      "------------------------------------------- \n",
      "/home/manish/fotos-form-download/image1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Action: emotion:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:  25%|██▌       | 1/4 [00:00<00:00,  8.22it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 777ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|█████     | 2/4 [00:01<00:01,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 747ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  75%|███████▌  | 3/4 [00:01<00:00,  1.39it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:03<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepface comparision\n",
      "----Deepface---\n",
      "Age:--- {36} ---\n",
      "Gender:--- {'Man'} ---\n",
      "Race:--- {'white'} ---\n",
      "Emotion:--- {'sad'} ---\n",
      "------------------------------------------- \n",
      "/home/manish/fotos-form-download/image299.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/manish/fotos-form-download/image99.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:  25%|██▌       | 1/4 [00:00<00:00,  7.24it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 741ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|█████     | 2/4 [00:01<00:01,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 785ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  75%|███████▌  | 3/4 [00:02<00:00,  1.32it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 829ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:02<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepface comparision\n",
      "----Deepface---\n",
      "Age:--- {28} ---\n",
      "Gender:--- {'Man'} ---\n",
      "Race:--- {'indian'} ---\n",
      "Emotion:--- {'angry'} ---\n",
      "------------------------------------------- \n",
      "/home/manish/fotos-form-download/image147.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Action: emotion:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:  25%|██▌       | 1/4 [00:00<00:00,  6.23it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 831ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|█████     | 2/4 [00:01<00:01,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 907ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  75%|███████▌  | 3/4 [00:02<00:00,  1.21it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 784ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:03<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepface comparision\n",
      "----Deepface---\n",
      "Age:--- {32} ---\n",
      "Gender:--- {'Man'} ---\n",
      "Race:--- {'white'} ---\n",
      "Emotion:--- {'happy'} ---\n",
      "------------------------------------------- \n",
      "/home/manish/fotos-form-download/image283.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/manish/fotos-form-download/image174.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:  25%|██▌       | 1/4 [00:00<00:00,  7.81it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 798ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|█████     | 2/4 [00:01<00:01,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 770ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  75%|███████▌  | 3/4 [00:02<00:00,  1.34it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 758ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:02<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepface comparision\n",
      "----Deepface---\n",
      "Age:--- {27} ---\n",
      "Gender:--- {'Man'} ---\n",
      "Race:--- {'white'} ---\n",
      "Emotion:--- {'surprise'} ---\n",
      "------------------------------------------- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: emotion:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:  25%|██▌       | 1/4 [00:00<00:00,  5.10it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 893ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|█████     | 2/4 [00:01<00:01,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 830ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  75%|███████▌  | 3/4 [00:02<00:00,  1.21it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 969ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:03<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepface comparision\n",
      "----Deepface---\n",
      "Age:--- {27} ---\n",
      "Gender:--- {'Man'} ---\n",
      "Race:--- {'white'} ---\n",
      "Emotion:--- {'sad'} ---\n",
      "------------------------------------------- \n",
      "/home/manish/fotos-form-download/image30.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Action: emotion:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:  25%|██▌       | 1/4 [00:00<00:00,  7.50it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 865ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|█████     | 2/4 [00:01<00:01,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 790ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  75%|███████▌  | 3/4 [00:02<00:00,  1.28it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 802ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:03<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepface comparision\n",
      "----Deepface---\n",
      "Age:--- {34} ---\n",
      "Gender:--- {'Man'} ---\n",
      "Race:--- {'latino hispanic'} ---\n",
      "Emotion:--- {'neutral'} ---\n",
      "------------------------------------------- \n",
      "/home/manish/fotos-form-download/image278.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Action: emotion:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: age:  25%|██▌       | 1/4 [00:00<00:00,  8.55it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 774ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: gender:  50%|█████     | 2/4 [00:01<00:01,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 788ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race:  75%|███████▌  | 3/4 [00:01<00:00,  1.34it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 756ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:02<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepface comparision\n",
      "----Deepface---\n",
      "Age:--- {30} ---\n",
      "Gender:--- {'Man'} ---\n",
      "Race:--- {'white'} ---\n",
      "Emotion:--- {'sad'} ---\n",
      "------------------------------------------- \n",
      "/home/manish/fotos-form-download/image82.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of picture analyzed by the 18\n",
      "average age:30.666666666666668\n",
      "-----------------Race------------------\n",
      "White: 14\n",
      "Black: 0\n",
      "Asian:0\n",
      "Indian: 1\n",
      "Unknown: 3\n",
      "---------Emotion------------------\n",
      "Angry: 2\n",
      "Disgust: 0\n",
      "fear: 0\n",
      "Hppy: 5\n",
      "sad: 4\n",
      "Suprise:0\n",
      "neutral: 7\n",
      "no object detected\n",
      "Time taken by deepface  is : 64.23547625541687seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "folder_dir = \"/home/manish/fotos-form-download\" #folder containing picture location to be evaluate\n",
    "save_dir= \"/home/manish/Documents\"   #saving of the temporary file\n",
    " \n",
    "\n",
    "##democlassi statstics evaluation\n",
    "demostatsMen = Stats(\"democlassi\",\"men\")\n",
    "demostatsMen.race = Stats.Race()\n",
    "demostatsMen.emotion = Stats.Emotion()\n",
    "\n",
    "demostatsWomen= Stats(\"democlassi\",\"women\")\n",
    "demostatsWomen.race = Stats.Race()\n",
    "demostatsWomen.emotion = Stats.Emotion()\n",
    "\n",
    "##deepface statstics evaluation\n",
    "deepstatsMen = Stats(\"deepface\",\"men\")\n",
    "deepstatsMen.race = Stats.Race()\n",
    "deepstatsMen.emotion = Stats.Emotion()\n",
    "\n",
    "deepstatsWomen= Stats(\"deepface\",\"women\")\n",
    "deepstatsWomen.race = Stats.Race()\n",
    "deepstatsWomen.emotion = Stats.Emotion()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#st = time.time()\n",
    "#evaluateDemoclassi(folder_dir,save_dir,demostatsMen,demostatsWomen)\n",
    "#et = time.time()\n",
    "\n",
    "\n",
    "#printStats(demostatsMen)\n",
    "#printStats(demostatsWomen)\n",
    "\n",
    "#print(\"Time taken by democlassi  is : \"+ str(et-st) + \"seconds\")\n",
    "\n",
    "\n",
    "st = time.time()\n",
    "evaluateDeepface(folder_dir,save_dir,deepstatsMen,deepstatsWomen)\n",
    "et = time.time()\n",
    "\n",
    "printStats(deepstatsMen)\n",
    "printStats(deepstatsWomen)\n",
    "print(\"Time taken by deepface  is : \" +str(et-st)+ \"seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
